#!/usr/bin/env python3
"""
ç¼ è®ºæŠ€æœ¯åˆ†æå·¥å…·
ç”¨äºåˆ†æè‚¡ç¥¨èµ°åŠ¿çš„ç¬”ã€çº¿æ®µã€ä¸­æ¢ã€èƒŒé©°ç­‰ç¼ è®ºæ¦‚å¿µ
"""

import akshare as ak
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from collections import deque
import warnings
warnings.filterwarnings('ignore')

class ChanLunAnalyzer:
    """ç¼ è®ºåˆ†æå™¨"""
    
    def __init__(self, symbol):
        self.symbol = symbol
        self.data = None
        self.bi_list = []  # ç¬”åˆ—è¡¨
        self.xianduan_list = []  # çº¿æ®µåˆ—è¡¨
        self.zhongshu_list = []  # ä¸­æ¢åˆ—è¡¨
        
    def get_data(self, period="1y"):
        """è·å–è‚¡ç¥¨æ•°æ®"""
        try:
            stock_data = ak.stock_zh_a_hist(symbol=self.symbol, period="daily")
            stock_data['æ—¥æœŸ'] = pd.to_datetime(stock_data['æ—¥æœŸ'])
            stock_data = stock_data.sort_values('æ—¥æœŸ')
            
            if period == "1y":
                start_date = datetime.now() - timedelta(days=365)
            elif period == "6m":
                start_date = datetime.now() - timedelta(days=180)
            else:
                start_date = datetime.now() - timedelta(days=90)
                
            stock_data = stock_data[stock_data['æ—¥æœŸ'] >= start_date]
            
            # è½¬æ¢æ•°æ®ç±»å‹
            stock_data['æ”¶ç›˜'] = pd.to_numeric(stock_data['æ”¶ç›˜'])
            stock_data['æœ€é«˜'] = pd.to_numeric(stock_data['æœ€é«˜'])
            stock_data['æœ€ä½'] = pd.to_numeric(stock_data['æœ€ä½'])
            stock_data['æˆäº¤é‡'] = pd.to_numeric(stock_data['æˆäº¤é‡'])
            
            self.data = stock_data.reset_index(drop=True)
            return self.data
            
        except Exception as e:
            print(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def find_fenxing(self, data):
        """è¯†åˆ«åˆ†å‹"""
        fenxing_list = []
        
        for i in range(1, len(data) - 1):
            current_high = data.iloc[i]['æœ€é«˜']
            current_low = data.iloc[i]['æœ€ä½']
            prev_high = data.iloc[i-1]['æœ€é«˜']
            prev_low = data.iloc[i-1]['æœ€ä½']
            next_high = data.iloc[i+1]['æœ€é«˜']
            next_low = data.iloc[i+1]['æœ€ä½']
            
            # é¡¶åˆ†å‹
            if current_high > prev_high and current_high > next_high:
                fenxing_list.append({
                    'type': 'é¡¶åˆ†å‹',
                    'index': i,
                    'date': data.iloc[i]['æ—¥æœŸ'],
                    'price': current_high,
                    'low': current_low
                })
            
            # åº•åˆ†å‹
            if current_low < prev_low and current_low < next_low:
                fenxing_list.append({
                    'type': 'åº•åˆ†å‹',
                    'index': i,
                    'date': data.iloc[i]['æ—¥æœŸ'],
                    'price': current_low,
                    'high': current_high
                })
        
        return fenxing_list
    
    def find_bi(self, data, fenxing_list):
        """è¯†åˆ«ç¬”"""
        bi_list = []
        
        if len(fenxing_list) < 2:
            return bi_list
        
        # ç¡®ä¿åˆ†å‹äº¤æ›¿å‡ºç°
        valid_fenxing = []
        last_type = None
        
        for fx in fenxing_list:
            if last_type is None or fx['type'] != last_type:
                valid_fenxing.append(fx)
                last_type = fx['type']
        
        # è¯†åˆ«ç¬”
        for i in range(len(valid_fenxing) - 1):
            current_fx = valid_fenxing[i]
            next_fx = valid_fenxing[i + 1]
            
            # ç¬”çš„å®šä¹‰ï¼šç›¸é‚»çš„é¡¶åˆ†å‹å’Œåº•åˆ†å‹
            if current_fx['type'] != next_fx['type']:
                # æ£€æŸ¥æ˜¯å¦æœ‰é‡å 
                if (current_fx['type'] == 'é¡¶åˆ†å‹' and 
                    current_fx['price'] > next_fx['price']):
                    bi_list.append({
                        'type': 'ä¸‹é™ç¬”',
                        'start_index': current_fx['index'],
                        'end_index': next_fx['index'],
                        'start_date': current_fx['date'],
                        'end_date': next_fx['date'],
                        'start_price': current_fx['price'],
                        'end_price': next_fx['price'],
                        'height': current_fx['price'] - next_fx['price']
                    })
                elif (current_fx['type'] == 'åº•åˆ†å‹' and 
                      current_fx['price'] < next_fx['price']):
                    bi_list.append({
                        'type': 'ä¸Šå‡ç¬”',
                        'start_index': current_fx['index'],
                        'end_index': next_fx['index'],
                        'start_date': current_fx['date'],
                        'end_date': next_fx['date'],
                        'start_price': current_fx['price'],
                        'end_price': next_fx['price'],
                        'height': next_fx['price'] - current_fx['price']
                    })
        
        return bi_list
    
    def find_xianduan(self, data, bi_list):
        """è¯†åˆ«çº¿æ®µ - ä¿®æ­£ç‰ˆæœ¬"""
        xianduan_list = []
        
        if len(bi_list) < 3:
            return xianduan_list
        
        # æ›´ç®€å•çš„çº¿æ®µå®šä¹‰ï¼šè¿ç»­3ç¬”ä»¥ä¸ŠåŒæ–¹å‘çš„èµ°åŠ¿æ„æˆçº¿æ®µ
        i = 0
        while i < len(bi_list) - 2:
            # æŸ¥æ‰¾è¿ç»­åŒæ–¹å‘çš„ç¬”
            first_bi = bi_list[i]
            current_type = first_bi['type']
            
            # æ”¶é›†è¿ç»­çš„åŒæ–¹å‘ç¬”
            consecutive_bi = [first_bi]
            j = i + 1
            
            while j < len(bi_list) and bi_list[j]['type'] == current_type:
                consecutive_bi.append(bi_list[j])
                j += 1
            
            # å¦‚æœè¿ç»­3ç¬”ä»¥ä¸ŠåŒæ–¹å‘ï¼Œæ„æˆçº¿æ®µ
            if len(consecutive_bi) >= 3:
                xianduan_list.append({
                    'type': current_type,
                    'bi_list': consecutive_bi.copy(),
                    'start_index': consecutive_bi[0]['start_index'],
                    'end_index': consecutive_bi[-1]['end_index'],
                    'start_date': consecutive_bi[0]['start_date'],
                    'end_date': consecutive_bi[-1]['end_date'],
                    'start_price': consecutive_bi[0]['start_price'],
                    'end_price': consecutive_bi[-1]['end_price'],
                    'height': abs(consecutive_bi[-1]['end_price'] - consecutive_bi[0]['start_price']),
                    'bi_count': len(consecutive_bi)
                })
                
                # è·³è¿‡å·²ç»å¤„ç†çš„ç¬”
                i = j
            else:
                i += 1
        
        return xianduan_list
    
    def find_zhongshu(self, data, xianduan_list):
        """è¯†åˆ«ä¸­æ¢ - ä¿®æ­£ç‰ˆæœ¬"""
        zhongshu_list = []
        
        if len(xianduan_list) < 3:
            return zhongshu_list
        
        # ä¸­æ¢å®šä¹‰ï¼šè¿ç»­ä¸‰ä¸ªçº¿æ®µçš„ä»·æ ¼é‡å åŒºåŸŸ
        for i in range(len(xianduan_list) - 2):
            xd1 = xianduan_list[i]
            xd2 = xianduan_list[i + 1] 
            xd3 = xianduan_list[i + 2]
            
            # è·å–æ¯ä¸ªçº¿æ®µçš„ä»·æ ¼åŒºé—´
            xd1_high = max(xd1['start_price'], xd1['end_price'])
            xd1_low = min(xd1['start_price'], xd1['end_price'])
            
            xd2_high = max(xd2['start_price'], xd2['end_price'])
            xd2_low = min(xd2['start_price'], xd2['end_price'])
            
            xd3_high = max(xd3['start_price'], xd3['end_price'])
            xd3_low = min(xd3['start_price'], xd3['end_price'])
            
            # è®¡ç®—é‡å åŒºåŸŸ
            overlap_low = max(xd1_low, xd2_low, xd3_low)
            overlap_high = min(xd1_high, xd2_high, xd3_high)
            
            if overlap_low < overlap_high:  # æœ‰é‡å åŒºåŸŸ
                zhongshu_list.append({
                    'start_index': min(xd1['start_index'], xd2['start_index'], xd3['start_index']),
                    'end_index': max(xd1['end_index'], xd2['end_index'], xd3['end_index']),
                    'upper': overlap_high,
                    'lower': overlap_low,
                    'center': (overlap_high + overlap_low) / 2,
                    'height': overlap_high - overlap_low,
                    'xianduan_count': 3,
                    'xd1': xd1, 'xd2': xd2, 'xd3': xd3
                })
        
        return zhongshu_list
    
    def find_beichi(self, data, bi_list, xianduan_list):
        """è¯†åˆ«èƒŒé©°"""
        beichi_list = []
        
        # ç¬”èƒŒé©°
        if len(bi_list) >= 2:
            for i in range(len(bi_list) - 1):
                current_bi = bi_list[i + 1]
                prev_bi = bi_list[i]
                
                if current_bi['type'] == prev_bi['type']:  # åŒæ–¹å‘
                    # æ¯”è¾ƒé«˜åº¦å’Œæˆäº¤é‡
                    current_volume = data.iloc[current_bi['start_index']:current_bi['end_index']]['æˆäº¤é‡'].sum()
                    prev_volume = data.iloc[prev_bi['start_index']:prev_bi['end_index']]['æˆäº¤é‡'].sum()
                    
                    # èƒŒé©°æ¡ä»¶ï¼šä»·æ ¼åˆ›æ–°é«˜/æ–°ä½ï¼Œä½†æˆäº¤é‡å‡å°‘
                    if (current_bi['type'] == 'ä¸Šå‡ç¬”' and 
                        current_bi['height'] > prev_bi['height'] and 
                        current_volume < prev_volume):
                        beichi_list.append({
                            'type': 'ç¬”èƒŒé©°ï¼ˆä¸Šå‡ï¼‰',
                            'index': current_bi['end_index'],
                            'date': current_bi['end_date'],
                            'price': current_bi['end_price']
                        })
                    elif (current_bi['type'] == 'ä¸‹é™ç¬”' and 
                          current_bi['height'] > prev_bi['height'] and 
                          current_volume < prev_volume):
                        beichi_list.append({
                            'type': 'ç¬”èƒŒé©°ï¼ˆä¸‹é™ï¼‰',
                            'index': current_bi['end_index'],
                            'date': current_bi['end_date'],
                            'price': current_bi['end_price']
                        })
        
        return beichi_list
    
    def find_buy_sell_points(self, data, zhongshu_list, beichi_list):
        """è¯†åˆ«ä¹°å–ç‚¹"""
        buy_points = []
        sell_points = []
        
        # åŸºäºä¸­æ¢çš„ä¹°å–ç‚¹
        for zhongshu in zhongshu_list:
            current_price = data.iloc[-1]['æ”¶ç›˜']
            
            # ç¬¬ä¸‰ç±»ä¹°ç‚¹ï¼šçªç ´ä¸­æ¢åå›è¸©ä¸ç ´
            if current_price > zhongshu['upper'] * 1.02:  # çªç ´2%
                buy_points.append({
                    'type': 'ç¬¬ä¸‰ç±»ä¹°ç‚¹',
                    'price': zhongshu['upper'],
                    'condition': 'çªç ´ä¸­æ¢åå›è¸©ä¸ç ´'
                })
            
            # ç¬¬ä¸‰ç±»å–ç‚¹ï¼šè·Œç ´ä¸­æ¢ååå¼¹ä¸è¿‡
            if current_price < zhongshu['lower'] * 0.98:  # è·Œç ´2%
                sell_points.append({
                    'type': 'ç¬¬ä¸‰ç±»å–ç‚¹',
                    'price': zhongshu['lower'],
                    'condition': 'è·Œç ´ä¸­æ¢ååå¼¹ä¸è¿‡'
                })
        
        # åŸºäºèƒŒé©°çš„ä¹°å–ç‚¹
        for beichi in beichi_list:
            if 'ä¸Šå‡èƒŒé©°' in beichi['type']:
                sell_points.append({
                    'type': 'èƒŒé©°å–ç‚¹',
                    'price': beichi['price'],
                    'condition': 'ä¸Šå‡èƒŒé©°'
                })
            elif 'ä¸‹é™èƒŒé©°' in beichi['type']:
                buy_points.append({
                    'type': 'èƒŒé©°ä¹°ç‚¹',
                    'price': beichi['price'],
                    'condition': 'ä¸‹é™èƒŒé©°'
                })
        
        return buy_points, sell_points
    
    def analyze_zoushi_type(self, xianduan_list):
        """åˆ†æèµ°åŠ¿ç±»å‹ - ä¿®æ­£ç‰ˆæœ¬"""
        if len(xianduan_list) < 2:
            return "æ— æ³•åˆ¤æ–­"
        
        # è®¡ç®—æœ€è¿‘å‡ ä¸ªçº¿æ®µçš„æ•´ä½“æ–¹å‘
        recent_xd = xianduan_list[-min(5, len(xianduan_list)):]
        
        # ç»Ÿè®¡ä¸Šå‡å’Œä¸‹é™çº¿æ®µçš„æ•°é‡
        up_count = sum(1 for xd in recent_xd if xd['type'] == 'ä¸Šå‡ç¬”')
        down_count = sum(1 for xd in recent_xd if xd['type'] == 'ä¸‹é™ç¬”')
        
        # è®¡ç®—ä»·æ ¼å˜åŒ–è¶‹åŠ¿
        start_price = recent_xd[0]['start_price']
        end_price = recent_xd[-1]['end_price']
        
        if up_count > down_count and end_price > start_price:
            return "ä¸Šæ¶¨è¶‹åŠ¿"
        elif down_count > up_count and end_price < start_price:
            return "ä¸‹è·Œè¶‹åŠ¿"
        else:
            return "ç›˜æ•´èµ°åŠ¿"
    
    def comprehensive_chan_analysis(self, data):
        """å®Œæ•´çš„ç¼ è®ºåˆ†æ"""
        print("å¼€å§‹ç¼ è®ºæŠ€æœ¯åˆ†æ...")
        
        # 1. è¯†åˆ«åˆ†å‹
        fenxing_list = self.find_fenxing(data)
        print(f"è¯†åˆ«åˆ° {len(fenxing_list)} ä¸ªåˆ†å‹")
        
        # 2. è¯†åˆ«ç¬”
        bi_list = self.find_bi(data, fenxing_list)
        print(f"è¯†åˆ«åˆ° {len(bi_list)} ç¬”")
        
        # 3. è¯†åˆ«çº¿æ®µ
        xianduan_list = self.find_xianduan(data, bi_list)
        print(f"è¯†åˆ«åˆ° {len(xianduan_list)} ä¸ªçº¿æ®µ")
        
        # 4. è¯†åˆ«ä¸­æ¢
        zhongshu_list = self.find_zhongshu(data, xianduan_list)
        print(f"è¯†åˆ«åˆ° {len(zhongshu_list)} ä¸ªä¸­æ¢")
        
        # 5. è¯†åˆ«èƒŒé©°
        beichi_list = self.find_beichi(data, bi_list, xianduan_list)
        print(f"è¯†åˆ«åˆ° {len(beichi_list)} ä¸ªèƒŒé©°")
        
        # 6. è¯†åˆ«ä¹°å–ç‚¹
        buy_points, sell_points = self.find_buy_sell_points(data, zhongshu_list, beichi_list)
        print(f"è¯†åˆ«åˆ° {len(buy_points)} ä¸ªä¹°ç‚¹, {len(sell_points)} ä¸ªå–ç‚¹")
        
        # 7. åˆ†æèµ°åŠ¿ç±»å‹
        zoushi_type = self.analyze_zoushi_type(xianduan_list)
        print(f"å½“å‰èµ°åŠ¿ç±»å‹: {zoushi_type}")
        
        return {
            'fenxing_list': fenxing_list,
            'bi_list': bi_list,
            'xianduan_list': xianduan_list,
            'zhongshu_list': zhongshu_list,
            'beichi_list': beichi_list,
            'buy_points': buy_points,
            'sell_points': sell_points,
            'zoushi_type': zoushi_type,
            'data': data
        }
    
    def generate_chan_report(self, chan_result):
        """ç”Ÿæˆç¼ è®ºåˆ†ææŠ¥å‘Š"""
        data = chan_result['data']
        current_price = data.iloc[-1]['æ”¶ç›˜']
        current_date = data.iloc[-1]['æ—¥æœŸ']
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ç¼ è®ºæŠ€æœ¯åˆ†ææŠ¥å‘Š                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ è‚¡ç¥¨ä»£ç : {self.symbol}                                        â•‘
â•‘ åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}	  â•‘
â•‘ å½“å‰ä»·æ ¼: Â¥{current_price:.2f}				  â•‘
â•‘ èµ°åŠ¿ç±»å‹: {chan_result['zoushi_type']}					  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£

ã€åˆ†å‹åˆ†æã€‘
è¯†åˆ«åˆ° {len(chan_result['fenxing_list'])} ä¸ªåˆ†å‹
æœ€è¿‘åˆ†å‹: {chan_result['fenxing_list'][-1]['type'] if chan_result['fenxing_list'] else 'æ— '}
ä»·æ ¼: Â¥{chan_result['fenxing_list'][-1]['price']:.2f} if chan_result['fenxing_list'] else 'æ— '

ã€ç¬”åˆ†æã€‘  
è¯†åˆ«åˆ° {len(chan_result['bi_list'])} ç¬”
æœ€è¿‘ä¸€ç¬”: {chan_result['bi_list'][-1]['type'] if chan_result['bi_list'] else 'æ— '}
é«˜åº¦: Â¥{chan_result['bi_list'][-1]['height']:.2f} if chan_result['bi_list'] else 'æ— '

ã€çº¿æ®µåˆ†æã€‘
è¯†åˆ«åˆ° {len(chan_result['xianduan_list'])} ä¸ªçº¿æ®µ
æœ€è¿‘çº¿æ®µ: {chan_result['xianduan_list'][-1]['type'] if chan_result['xianduan_list'] else 'æ— '}
"""

        # ä¸­æ¢åˆ†æ
        if chan_result['zhongshu_list']:
            latest_zhongshu = chan_result['zhongshu_list'][-1]
            report += f"""
ã€ä¸­æ¢åˆ†æã€‘
è¯†åˆ«åˆ° {len(chan_result['zhongshu_list'])} ä¸ªä¸­æ¢
æœ€è¿‘ä¸­æ¢èŒƒå›´: Â¥{latest_zhongshu['lower']:.2f} - Â¥{latest_zhongshu['upper']:.2f}
ä¸­æ¢ä¸­å¿ƒ: Â¥{latest_zhongshu['center']:.2f}
"""
        
        # èƒŒé©°åˆ†æ
        if chan_result['beichi_list']:
            report += f"""
ã€èƒŒé©°åˆ†æã€‘
è¯†åˆ«åˆ° {len(chan_result['beichi_list'])} ä¸ªèƒŒé©°
æœ€è¿‘èƒŒé©°: {chan_result['beichi_list'][-1]['type']}
ä»·æ ¼: Â¥{chan_result['beichi_list'][-1]['price']:.2f}
"""
        
        # ä¹°å–ç‚¹åˆ†æ
        if chan_result['buy_points']:
            report += f"""
ã€ä¹°ç‚¹åˆ†æã€‘
è¯†åˆ«åˆ° {len(chan_result['buy_points'])} ä¸ªä¹°ç‚¹
"""
            for bp in chan_result['buy_points']:
                report += f"{bp['type']}: Â¥{bp['price']:.2f} ({bp['condition']})\n"
        
        if chan_result['sell_points']:
            report += f"""
ã€å–ç‚¹åˆ†æã€‘
è¯†åˆ«åˆ° {len(chan_result['sell_points'])} ä¸ªå–ç‚¹
"""
            for sp in chan_result['sell_points']:
                report += f"{sp['type']}: Â¥{sp['price']:.2f} ({sp['condition']})\n"
        
        # æ“ä½œå»ºè®®
        report += """
ã€ç¼ è®ºæ“ä½œå»ºè®®ã€‘
"""
        if chan_result['buy_points'] and not chan_result['sell_points']:
            report += "ğŸŸ¢ å»ºè®®å…³æ³¨ä¹°å…¥æœºä¼š\n"
        elif chan_result['sell_points'] and not chan_result['buy_points']:
            report += "ğŸ”´ å»ºè®®å…³æ³¨å–å‡ºæœºä¼š\n"
        elif chan_result['buy_points'] and chan_result['sell_points']:
            report += "ğŸŸ¡ å¤šç©ºäº¤ç»‡ï¼Œè°¨æ…æ“ä½œ\n"
        else:
            report += "âšª ç­‰å¾…æ˜ç¡®ä¿¡å·\n"
        
        report += """
ã€ç¼ è®ºé£é™©æç¤ºã€‘
1. ç¼ è®ºåˆ†æåŸºäºå†å²æ•°æ®ï¼Œä¸èƒ½ä¿è¯æœªæ¥èµ°åŠ¿
2. éœ€è¦ç»“åˆå…¶ä»–æŠ€æœ¯æŒ‡æ ‡å’ŒåŸºæœ¬é¢åˆ†æ
3. ä¸¥æ ¼è®¾ç½®æ­¢æŸï¼Œæ§åˆ¶ä»“ä½é£é™©
4. ä¸­æ¢çªç ´å¯èƒ½å¤±è´¥ï¼Œéœ€è¦ç¡®è®¤

ç¼ è®ºæ ¸å¿ƒæ€æƒ³ï¼šèµ°åŠ¿ç»ˆå®Œç¾
ä»»ä½•èµ°åŠ¿éƒ½ä¼šå®Œæˆï¼Œå…³é”®æ˜¯æ‰¾åˆ°è½¬æŠ˜ç‚¹
"""
        
        report += "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        return report
    
    def plot_chan_analysis(self, chan_result, days=60):
        """ç»˜åˆ¶ç¼ è®ºåˆ†æå›¾è¡¨"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.dates as mdates
            from datetime import datetime
            
            # è·å–æœ€è¿‘dayså¤©çš„æ•°æ®
            data = chan_result['data'].tail(days).copy()
            dates = pd.to_datetime(data['æ—¥æœŸ'])
            
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10), sharex=True)
            
            # ç»˜åˆ¶Kçº¿
            ax1.plot(dates, data['æ”¶ç›˜'], 'b-', linewidth=1, label='æ”¶ç›˜ä»·')
            ax1.fill_between(dates, data['æœ€ä½'], data['æœ€é«˜'], alpha=0.3, color='gray', label='é«˜ä½ä»·åŒºé—´')
            
            # æ ‡è®°åˆ†å‹
            for fx in chan_result['fenxing_list']:
                fx_date = pd.to_datetime(fx['date'])
                if fx_date in dates.values:
                    if fx['type'] == 'é¡¶åˆ†å‹':
                        ax1.plot(fx_date, fx['price'], 'rv', markersize=8, label='é¡¶åˆ†å‹' if fx == chan_result['fenxing_list'][0] else "")
                    else:
                        ax1.plot(fx_date, fx['price'], 'g^', markersize=8, label='åº•åˆ†å‹' if fx == chan_result['fenxing_list'][0] else "")
            
            # æ ‡è®°ç¬”
            for bi in chan_result['bi_list']:
                start_date = pd.to_datetime(bi['start_date'])
                end_date = pd.to_datetime(bi['end_date'])
                if start_date in dates.values and end_date in dates.values:
                    color = 'red' if bi['type'] == 'ä¸‹é™ç¬”' else 'green'
                    ax1.plot([start_date, end_date], [bi['start_price'], bi['end_price']], 
                            color=color, linewidth=2, alpha=0.7)
            
            # æ ‡è®°ä¸­æ¢
            for zs in chan_result['zhongshu_list']:
                start_idx = max(0, zs['start_index'] - len(data) + days)
                end_idx = min(days - 1, zs['end_index'] - len(data) + days)
                
                if start_idx < end_idx:
                    start_date = dates.iloc[start_idx]
                    end_date = dates.iloc[end_idx]
                    
                    # ç»˜åˆ¶ä¸­æ¢çŸ©å½¢
                    ax1.axhspan(zs['lower'], zs['upper'], xmin=start_idx/days, xmax=end_idx/days, 
                               alpha=0.3, color='yellow', label='ä¸­æ¢' if zs == chan_result['zhongshu_list'][0] else "")
            
            ax1.set_title(f'{self.symbol} ç¼ è®ºæŠ€æœ¯åˆ†æ', fontsize=16)
            ax1.set_ylabel('ä»·æ ¼ (å…ƒ)')
            ax1.grid(True, alpha=0.3)
            ax1.legend(loc='upper left')
            
            # ç»˜åˆ¶æˆäº¤é‡
            ax2.bar(dates, data['æˆäº¤é‡'], alpha=0.6, color='blue')
            ax2.set_ylabel('æˆäº¤é‡')
            ax2.grid(True, alpha=0.3)
            
            # è®¾ç½®xè½´æ ¼å¼
            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
            ax2.xaxis.set_major_locator(mdates.DayLocator(interval=max(1, days//10)))
            plt.xticks(rotation=45)
            
            plt.tight_layout()
            plt.show()
            
        except ImportError:
            print("matplotlib æœªå®‰è£…ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨")
        except Exception as e:
            print(f"ç»˜åˆ¶å›¾è¡¨å¤±è´¥: {e}")

def analyze_zijin_mining_chan_lun():
    """ç´«é‡‘çŸ¿ä¸šç¼ è®ºåˆ†æä¸“é¡¹å‡½æ•°"""
    print("=" * 60)
    print("ç´«é‡‘çŸ¿ä¸šï¼ˆ601899ï¼‰ç¼ è®ºæŠ€æœ¯åˆ†æ")
    print("=" * 60)
    print(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # åˆ›å»ºç¼ è®ºåˆ†æå™¨
    analyzer = ChanLunAnalyzer("601899")
    
    # è·å–æ•°æ®
    print("æ­£åœ¨è·å–ç´«é‡‘çŸ¿ä¸šå†å²æ•°æ®...")
    data = analyzer.get_data("1y")
    
    if data.empty:
        print("è·å–æ•°æ®å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
        return
    
    print(f"è·å–åˆ° {len(data)} ä¸ªäº¤æ˜“æ—¥æ•°æ®")
    print(f"æ—¶é—´èŒƒå›´: {data.iloc[0]['æ—¥æœŸ'].strftime('%Y-%m-%d')} è‡³ {data.iloc[-1]['æ—¥æœŸ'].strftime('%Y-%m-%d')}")
    print(f"ä»·æ ¼åŒºé—´: Â¥{data['æ”¶ç›˜'].min():.2f} - Â¥{data['æ”¶ç›˜'].max():.2f}")
    print()
    
    # æ‰§è¡Œç¼ è®ºåˆ†æ
    print("å¼€å§‹æ‰§è¡Œç¼ è®ºåˆ†æ...")
    chan_result = analyzer.comprehensive_chan_analysis(data)
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    print("\nç”Ÿæˆç¼ è®ºåˆ†ææŠ¥å‘Š...")
    report = analyzer.generate_chan_report(chan_result)
    print(report)
    
    # ç»˜åˆ¶åˆ†æå›¾è¡¨
    print("\nç»˜åˆ¶ç¼ è®ºåˆ†æå›¾è¡¨...")
    analyzer.plot_chan_analysis(chan_result, days=120)
    
    # ä¸“é¡¹åˆ†æ
    print("\nã€ç´«é‡‘çŸ¿ä¸šä¸“é¡¹ç¼ è®ºåˆ†æã€‘")
    
    # 1. èµ°åŠ¿ç±»å‹åˆ†æ
    zoushi_type = chan_result['zoushi_type']
    print(f"å½“å‰èµ°åŠ¿ç±»å‹: {zoushi_type}")
    
    # 2. ä¸­æ¢åˆ†æ
    if chan_result['zhongshu_list']:
        latest_zhongshu = chan_result['zhongshu_list'][-1]
        current_price = data.iloc[-1]['æ”¶ç›˜']
        
        print(f"\næœ€æ–°ä¸­æ¢åˆ†æ:")
        print(f"ä¸­æ¢èŒƒå›´: Â¥{latest_zhongshu['lower']:.2f} - Â¥{latest_zhongshu['upper']:.2f}")
        print(f"å½“å‰ä»·æ ¼: Â¥{current_price:.2f}")
        
        if current_price > latest_zhongshu['upper']:
            print("ğŸŸ¢ å½“å‰ä»·æ ¼åœ¨ä¸­æ¢ä¸Šæ–¹ï¼Œå…³æ³¨ç¬¬ä¸‰ç±»ä¹°ç‚¹")
        elif current_price < latest_zhongshu['lower']:
            print("ğŸ”´ å½“å‰ä»·æ ¼åœ¨ä¸­æ¢ä¸‹æ–¹ï¼Œå…³æ³¨ç¬¬ä¸‰ç±»å–ç‚¹")
        else:
            print("ğŸŸ¡ å½“å‰ä»·æ ¼åœ¨ä¸­æ¢å†…éƒ¨ï¼Œéœ‡è¡æ•´ç†")
    
    # 3. ä¹°å–ç‚¹åˆ†æ
    if chan_result['buy_points']:
        print(f"\nä¹°å…¥ä¿¡å·: {len(chan_result['buy_points'])}ä¸ª")
        for bp in chan_result['buy_points']:
            print(f"  - {bp['type']}: Â¥{bp['price']:.2f}")
    
    if chan_result['sell_points']:
        print(f"\nå–å‡ºä¿¡å·: {len(chan_result['sell_points'])}ä¸ª")
        for sp in chan_result['sell_points']:
            print(f"  - {sp['type']}: Â¥{sp['price']:.2f}")
    
    # 4. èƒŒé©°åˆ†æ
    if chan_result['beichi_list']:
        print(f"\nèƒŒé©°è­¦å‘Š: {len(chan_result['beichi_list'])}ä¸ª")
        for bc in chan_result['beichi_list']:
            print(f"  - {bc['type']}: Â¥{bc['price']:.2f}")
    
    # 5. æ“ä½œå»ºè®®
    print(f"\nã€ç¼ è®ºæ“ä½œå»ºè®®ã€‘")
    if zoushi_type == "ä¸Šæ¶¨è¶‹åŠ¿":
        print("ğŸŸ¢ æ•´ä½“ä¸Šæ¶¨è¶‹åŠ¿ï¼Œé€¢ä½å…³æ³¨ä¹°å…¥æœºä¼š")
        print("ğŸ“ˆ å…³æ³¨å›è°ƒä¸åˆ›æ–°ä½çš„ä¹°å…¥ç‚¹")
    elif zoushi_type == "ä¸‹è·Œè¶‹åŠ¿":
        print("ğŸ”´ æ•´ä½“ä¸‹è·Œè¶‹åŠ¿ï¼Œè°¨æ…æ“ä½œ")
        print("ğŸ“‰ ç­‰å¾…æ˜ç¡®çš„åº•éƒ¨ä¿¡å·")
    else:
        print("ğŸŸ¡ ç›˜æ•´èµ°åŠ¿ï¼Œé«˜æŠ›ä½å¸")
        print("ğŸ“Š å…³æ³¨ä¸­æ¢çªç ´æ–¹å‘")
    
    print(f"\nã€é£é™©æ§åˆ¶ã€‘")
    print("âš ï¸  ä¸¥æ ¼è®¾ç½®æ­¢æŸï¼Œæ§åˆ¶å•åªè‚¡ç¥¨ä»“ä½")
    print("âš ï¸  ç¼ è®ºåˆ†æéœ€ç»“åˆåŸºæœ¬é¢å’Œå¸‚åœºç¯å¢ƒ")
    print("âš ï¸  ä¸­æ¢çªç ´å¯èƒ½å¤±è´¥ï¼Œéœ€è¦ç¡®è®¤")
    
    print("=" * 60)
    print("ç¼ è®ºåˆ†æå®Œæˆï¼Œä»…ä¾›å‚è€ƒ")
    print("=" * 60)

if __name__ == "__main__":
    analyze_zijin_mining_chan_lun()