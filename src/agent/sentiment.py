from typing import Any, List, Optional, Dict

from pydantic import Field

from src.agent.mcp import MCPAgent
from src.prompt.mcp import NEXT_STEP_PROMPT_ZN
from src.prompt.sentiment import SENTIMENT_SYSTEM_PROMPT
from src.schema import Message
from src.tool import Terminate, ToolCollection
from src.tool.sentiment import SentimentTool
from src.tool.web_search import WebSearch

import logging
logger = logging.getLogger(__name__)


class SentimentAgent(MCPAgent):
    """Sentiment analysis agent focused on market sentiment and news."""

    name: str = "sentiment_agent"
    description: str = "Analyzes market sentiment, news, and social media for insights on stock performance."
    system_prompt: str = SENTIMENT_SYSTEM_PROMPT
    next_step_prompt: str = NEXT_STEP_PROMPT_ZN

    # Initialize with FinGenius tools with proper type annotation
    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            SentimentTool(),
            WebSearch(),
            Terminate(),
        )
    )

    special_tool_names: List[str] = Field(default_factory=lambda: [Terminate().name])

    async def run(
        self, request: Optional[str] = None, stock_code: Optional[str] = None
    ) -> Any:
        """Run sentiment analysis on the given stock.

        Args:
            request: Optional initial request to process. If provided, overrides stock_code parameter.
            stock_code: The stock code/ticker to analyze

        Returns:
            Dictionary containing sentiment analysis results
        """
        # If stock_code is provided but request is not, create request from stock_code
        if stock_code and not request:
            # Set up system message about the stock being analyzed
            self.memory.add_message(
                Message.system_message(
                    f"ä½ æ­£åœ¨åˆ†æžè‚¡ç¥¨ {stock_code} çš„å¸‚åœºæƒ…ç»ªã€‚è¯·æ”¶é›†ç›¸å…³æ–°é—»ã€ç¤¾äº¤åª’ä½“æ•°æ®ï¼Œå¹¶è¯„ä¼°æ•´ä½“æƒ…ç»ªã€‚"
                )
            )
            request = f"è¯·åˆ†æž {stock_code} çš„å¸‚åœºæƒ…ç»ªå’Œç›¸å…³æ–°é—»ã€‚"

        # Call parent implementation with the request
        return await super().run(request)

    async def analyze(self, stock_code: str, **kwargs) -> Dict:
        """æ‰§è¡Œèˆ†æƒ…åˆ†æž"""
        try:
            logger.info(f"å¼€å§‹èˆ†æƒ…åˆ†æž: {stock_code}")
            
            # ç¡®ä¿å·¥å…·æ‰§è¡Œ - æ·»åŠ å¼ºåˆ¶æ‰§è¡Œé€»è¾‘
            analysis_tasks = []
            
            # 1. å¼ºåˆ¶æ‰§è¡Œæ–°é—»æœç´¢
            try:
                news_result = await self.tool_call("web_search", {
                    "query": f"{stock_code} è‚¡ç¥¨ æœ€æ–°æ¶ˆæ¯ èˆ†æƒ…",
                    "max_results": 10
                })
                if news_result and news_result.success:
                    analysis_tasks.append(("news_search", news_result.data))
                    logger.info(f"æ–°é—»æœç´¢æˆåŠŸ: {stock_code}")
                else:
                    logger.warning(f"æ–°é—»æœç´¢å¤±è´¥: {stock_code}")
            except Exception as e:
                logger.error(f"æ–°é—»æœç´¢å¼‚å¸¸: {stock_code}, {str(e)}")
            
            # 2. å¼ºåˆ¶æ‰§è¡Œç¤¾äº¤åª’ä½“åˆ†æž
            try:
                social_result = await self.tool_call("web_search", {
                    "query": f"{stock_code} è‚¡å§ è®¨è®º æƒ…ç»ª",
                    "max_results": 5
                })
                if social_result and social_result.success:
                    analysis_tasks.append(("social_media", social_result.data))
                    logger.info(f"ç¤¾äº¤åª’ä½“åˆ†æžæˆåŠŸ: {stock_code}")
                else:
                    logger.warning(f"ç¤¾äº¤åª’ä½“åˆ†æžå¤±è´¥: {stock_code}")
            except Exception as e:
                logger.error(f"ç¤¾äº¤åª’ä½“åˆ†æžå¼‚å¸¸: {stock_code}, {str(e)}")
            
            # 3. å¼ºåˆ¶æ‰§è¡Œèˆ†æƒ…åˆ†æžå·¥å…·
            try:
                sentiment_result = await self.tool_call("sentiment_analysis", {
                    "stock_code": stock_code,
                    "analysis_type": "comprehensive"
                })
                if sentiment_result and sentiment_result.success:
                    analysis_tasks.append(("sentiment_analysis", sentiment_result.data))
                    logger.info(f"èˆ†æƒ…åˆ†æžå·¥å…·æˆåŠŸ: {stock_code}")
                else:
                    logger.warning(f"èˆ†æƒ…åˆ†æžå·¥å…·å¤±è´¥: {stock_code}")
            except Exception as e:
                logger.error(f"èˆ†æƒ…åˆ†æžå·¥å…·å¼‚å¸¸: {stock_code}, {str(e)}")
            
            # 4. ç»¼åˆåˆ†æžç»“æžœ
            if analysis_tasks:
                summary = self._generate_comprehensive_summary(analysis_tasks, stock_code)
                logger.info(f"èˆ†æƒ…åˆ†æžå®Œæˆ: {stock_code}, æ‰§è¡Œäº† {len(analysis_tasks)} ä¸ªä»»åŠ¡")
                return {
                    "success": True,
                    "analysis_count": len(analysis_tasks),
                    "summary": summary,
                    "tasks_executed": [task[0] for task in analysis_tasks]
                }
            else:
                logger.warning(f"èˆ†æƒ…åˆ†æžæ²¡æœ‰æˆåŠŸæ‰§è¡Œä»»ä½•ä»»åŠ¡: {stock_code}")
                return {
                    "success": False,
                    "analysis_count": 0,
                    "summary": "æ— æ³•èŽ·å–èˆ†æƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥å’Œæ•°æ®æº",
                    "tasks_executed": []
                }
                
        except Exception as e:
            logger.error(f"èˆ†æƒ…åˆ†æžå¤±è´¥: {stock_code}, {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "analysis_count": 0,
                "summary": f"èˆ†æƒ…åˆ†æžå¼‚å¸¸: {str(e)}"
            }
    
    def _generate_comprehensive_summary(self, analysis_tasks: List, stock_code: str) -> str:
        """ç”Ÿæˆç»¼åˆèˆ†æƒ…åˆ†æžæŠ¥å‘Š"""
        try:
            summary_parts = [f"## {stock_code} èˆ†æƒ…åˆ†æžæŠ¥å‘Š\n"]
            
            for task_name, task_data in analysis_tasks:
                if task_name == "news_search":
                    summary_parts.append("### ðŸ“° æ–°é—»èˆ†æƒ…")
                    summary_parts.append(f"- æœç´¢åˆ° {len(task_data.get('results', []))} æ¡ç›¸å…³æ–°é—»")
                    summary_parts.append(f"- æ•´ä½“æƒ…ç»ªå€¾å‘: {self._analyze_news_sentiment(task_data)}")
                    
                elif task_name == "social_media":
                    summary_parts.append("### ðŸ’¬ ç¤¾äº¤åª’ä½“æƒ…ç»ª")
                    summary_parts.append(f"- æœç´¢åˆ° {len(task_data.get('results', []))} æ¡ç›¸å…³è®¨è®º")
                    summary_parts.append(f"- æŠ•èµ„è€…æƒ…ç»ª: {self._analyze_social_sentiment(task_data)}")
                    
                elif task_name == "sentiment_analysis":
                    summary_parts.append("### ðŸ“Š ä¸“ä¸šèˆ†æƒ…åˆ†æž")
                    summary_parts.append(f"- æƒ…ç»ªæŒ‡æ•°: {task_data.get('sentiment_score', 'N/A')}")
                    summary_parts.append(f"- é£Žé™©ç­‰çº§: {task_data.get('risk_level', 'N/A')}")
            
            return "\n".join(summary_parts)
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆèˆ†æƒ…åˆ†æžæŠ¥å‘Šå¤±è´¥: {str(e)}")
            return f"èˆ†æƒ…åˆ†æžæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _analyze_news_sentiment(self, data: Dict) -> str:
        """åˆ†æžæ–°é—»æƒ…ç»ª"""
        try:
            results = data.get('results', [])
            if not results:
                return "ä¸­æ€§"
            
            # ç®€å•çš„å…³é”®è¯æƒ…ç»ªåˆ†æž
            positive_keywords = ["ä¸Šæ¶¨", "åˆ©å¥½", "çªç ´", "å¢žé•¿", "çœ‹å¥½"]
            negative_keywords = ["ä¸‹è·Œ", "åˆ©ç©º", "æš´è·Œ", "é£Žé™©", "äºæŸ"]
            
            positive_count = 0
            negative_count = 0
            
            for result in results:
                text = result.get('snippet', '') + result.get('title', '')
                for keyword in positive_keywords:
                    if keyword in text:
                        positive_count += 1
                for keyword in negative_keywords:
                    if keyword in text:
                        negative_count += 1
            
            if positive_count > negative_count:
                return "åæ­£é¢"
            elif negative_count > positive_count:
                return "åè´Ÿé¢"
            else:
                return "ä¸­æ€§"
        except:
            return "ä¸­æ€§"
    
    def _analyze_social_sentiment(self, data: Dict) -> str:
        """åˆ†æžç¤¾äº¤åª’ä½“æƒ…ç»ª"""
        try:
            results = data.get('results', [])
            if not results:
                return "å¹³æ·¡"
            
            # ç®€å•çš„è®¨è®ºçƒ­åº¦åˆ†æž
            discussion_keywords = ["ä¹°å…¥", "å–å‡º", "æŒæœ‰", "çœ‹æ¶¨", "çœ‹è·Œ"]
            keyword_count = 0
            
            for result in results:
                text = result.get('snippet', '') + result.get('title', '')
                for keyword in discussion_keywords:
                    if keyword in text:
                        keyword_count += 1
            
            if keyword_count >= 5:
                return "æ´»è·ƒ"
            elif keyword_count >= 2:
                return "ä¸€èˆ¬"
            else:
                return "å¹³æ·¡"
        except:
            return "å¹³æ·¡"
